{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c4a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cce7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=mnist_dataset['train']\n",
    "testdf=mnist_dataset['test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36868f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimage=[]\n",
    "trainlabel=[]\n",
    "testimage=[]\n",
    "testlabel=[]\n",
    "for image, label in traindf:\n",
    "    trainimage.append(image.numpy().squeeze()) \n",
    "    trainlabel.append(label.numpy())\n",
    "\n",
    "for image, label in testdf:\n",
    "    testimage.append(image.numpy().squeeze()) \n",
    "    testlabel.append(label.numpy())\n",
    "\n",
    "# trainimage=np.array([trainimage])\n",
    "# trainlabel=np.array([testlabel])\n",
    "# testimage=np.array([testimage])\n",
    "# testlabel=np.array([testdf])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e56286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Test images shape: (60000, 28, 28)\n",
      "Test labels shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert training data\n",
    "X_train = np.array(trainimage)  # Images (features)\n",
    "y_train = np.array(trainlabel)  # Labels (targets)\n",
    "\n",
    "# Convert test data\n",
    "X_test = np.array(testimage)    # Images (features)\n",
    "y_test = np.array(testlabel)    # Labels (targets)\n",
    "\n",
    "print(\"Training images shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Test images shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c1ab401",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0  # Scale to [0, 1]\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4080482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1)  # Adds channel dimension (e.g., for grayscale)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13c3fecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)  # e.g., (60000, 28, 28, 1)\n",
    "print(\"y_train shape:\", y_train.shape)  # e.g., (60000,) or (60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97d509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380379d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(testlabel[20])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(testimage[20], cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f190a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract one batch (or example) from the dataset\n",
    "for image, label in traindf.take(1):\n",
    "    # Convert TensorFlow tensors to numpy arrays\n",
    "    image_np = image.numpy().squeeze()  # Shape: (28, 28, 1) â†’ (28, 28)\n",
    "    label_np = label.numpy()\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(image_np, cmap='Blues')\n",
    "    plt.title(f\"Label: {label_np}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c1ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f78cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81fd9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when creating a layer think about how the array or layer interacts instead of each individual node\n",
    "class Layer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.weights = np.random.randn(input_dim, output_dim) * 0.01\n",
    "        self.bias = np.zeros((1, output_dim))#np.zeros creates an array of given length filled with zero\n",
    "    \n",
    "    def forward(self,input):\n",
    "        self.input=input\n",
    "        self.z=(np.dot(input,self.weights)+self.bias)\n",
    "        self.z=relu(self.z)\n",
    "        return self.z\n",
    "    \n",
    "    def backward(self, grad, learning_rate):\n",
    "        delta = grad * relu_derivative(self.z)\n",
    "        dW = np.dot(self.input.T, delta)\n",
    "        db = np.sum(delta, axis=0, keepdims=True)\n",
    "        dW = np.clip(dW, -1, 1)\n",
    "        db = np.clip(db, -1, 1)\n",
    "        self.weights -= learning_rate * dW\n",
    "        self.bias -= learning_rate * db\n",
    "        grad_prev = np.dot(delta, self.weights.T)\n",
    "        return grad_prev\n",
    "    \n",
    "\n",
    "class Outputlayer(Layer):\n",
    "    def forward(self, input):\n",
    "        self.input=input\n",
    "        self.z=(np.dot(input,self.weights)+self.bias)\n",
    "        self.z=softmax(self.z)\n",
    "        return self.z\n",
    "    \n",
    "    def backward(self, grad, learning_rate):\n",
    "        dW = np.dot(self.input.T, grad)\n",
    "        db = np.sum(grad, axis=0, keepdims=True)\n",
    "        dW = np.clip(dW, -1, 1)\n",
    "        db = np.clip(db, -1, 1)\n",
    "        self.weights -= learning_rate * dW\n",
    "        self.bias -= learning_rate * db\n",
    "        return np.dot(grad, self.weights.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6343ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size=1):\n",
    "        self.layers = []\n",
    "        sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            self.layers.append(Layer(sizes[i], sizes[i+1]))\n",
    "        self.layers.append(Outputlayer(hidden_sizes[-1], output_size))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        a = X\n",
    "        for layer in self.layers:\n",
    "            a = layer.forward(a)\n",
    "        return a\n",
    "    \n",
    "    def backward(self, X, y, learning_rate):\n",
    "        y_pred = self.forward(X)\n",
    "        m = X.shape[0]\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        grad = (y_pred - y) / m\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7543a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( input_size, hidden_units, epochs=1000, lr=0.001):\n",
    "    X_train, y_train = load_data(\"train.npz\")\n",
    "    X_val, y_val = load_data(\"val.npz\")\n",
    "    model = NeuralNetwork(input_size=input_size, hidden_sizes=hidden_units, output_size=1)\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = np.mean((y_pred - y_train) ** 2)\n",
    "        model.backward(X_train, y_train, lr)\n",
    "        val_pred = model.forward(X_val)\n",
    "        val_loss = np.mean((val_pred - y_val) ** 2)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Train Loss: {loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9fa1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    X_test, y_test = load_data(\"test.npz\")\n",
    "    y_pred = model.forward(X_test)\n",
    "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)).mean()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
